{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Global config variables\n",
    "num_steps = 5 # number of truncated backprop steps ('n' in the discussion above)\n",
    "batch_size = 200\n",
    "num_classes = 2\n",
    "state_size = 4\n",
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gen_data(size=1000000):\n",
    "    X = np.array(np.random.choice(2, size=(size,)))\n",
    "    Y = []\n",
    "    for i in range(size):\n",
    "        threshold = 0.5\n",
    "        if X[i-3] == 1:\n",
    "            threshold += 0.5\n",
    "        if X[i-8] == 1:\n",
    "            threshold -= 0.25\n",
    "        if np.random.rand() > threshold:\n",
    "            Y.append(0)\n",
    "        else:\n",
    "            Y.append(1)\n",
    "    return X, np.array(Y)\n",
    "\n",
    "# adapted from https://github.com/tensorflow/tensorflow/blob/master/tensorflow/models/rnn/ptb/reader.py\n",
    "def gen_batch(raw_data, batch_size, num_steps):\n",
    "    raw_x, raw_y = raw_data\n",
    "    data_length = len(raw_x)\n",
    "\n",
    "    # partition raw data into batches and stack them vertically in a data matrix\n",
    "    batch_partition_length = data_length // batch_size\n",
    "    data_x = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    data_y = np.zeros([batch_size, batch_partition_length], dtype=np.int32)\n",
    "    for i in range(batch_size):\n",
    "        data_x[i] = raw_x[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "        data_y[i] = raw_y[batch_partition_length * i:batch_partition_length * (i + 1)]\n",
    "    # further divide batch partitions into num_steps for truncated backprop\n",
    "    epoch_size = batch_partition_length // num_steps\n",
    "\n",
    "    for i in range(epoch_size):\n",
    "        x = data_x[:, i * num_steps:(i + 1) * num_steps]\n",
    "        y = data_y[:, i * num_steps:(i + 1) * num_steps]\n",
    "        yield (x, y)\n",
    "\n",
    "def gen_epochs(n, num_steps):\n",
    "    for i in range(n):\n",
    "        yield gen_batch(gen_data(), batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Placeholders\n",
    "\"\"\"\n",
    "x = tf.placeholder(tf.int32, [batch_size, num_steps], name=\"input_placeholder\")\n",
    "y = tf.placeholder(tf.int32, [batch_size, num_steps], name=\"output_placeholder\")\n",
    "init_state = tf.zeros([batch_size, state_size])\n",
    "\n",
    "\"\"\"\n",
    "RNN Inputs\n",
    "\"\"\"\n",
    "# Turn our x placeholder into a list of one-hot tensors:\n",
    "x_one_hot = tf.one_hot(x, num_classes)\n",
    "rnn_inputs = tf.unstack(x_one_hot, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Definition of rnn_cell\n",
    "\"\"\"\n",
    "with tf.variable_scope(\"rnn_cell\"):\n",
    "    W = tf.get_variable(\"W\", [num_classes + state_size, state_size])\n",
    "    b = tf.get_variable(\"b\", [state_size], initializer=tf.constant_initializer(0.0))\n",
    "\n",
    "def rnn_cell(rnn_input, state):\n",
    "    with tf.variable_scope(\"rnn_cell\", reuse=True):\n",
    "        W = tf.get_variable(\"W\", [num_classes + state_size, state_size])\n",
    "        b = tf.get_variable(\"b\", [state_size], initializer=tf.constant_initializer(0.0))\n",
    "    return tf.tanh(tf.matmul(tf.concat([rnn_input, state], 1), W) + b)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Adding rnn_cells to graph\n",
    "\"\"\"\n",
    "\n",
    "state = init_state\n",
    "rnn_outputs = []\n",
    "for rnn_input in rnn_inputs:\n",
    "    state = rnn_cell(rnn_input, state)\n",
    "    rnn_outputs.append(state)\n",
    "final_state = rnn_outputs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prediction, loss, training step\n",
    "\n",
    "Losses is similar to the \"sequence_loss\" function from Tensorflow's API, except that here we are using a list of\n",
    "2D tensors, instead of a 3D tensor\n",
    "\"\"\"\n",
    "\n",
    "# logits and predictions\n",
    "with tf.variable_scope(\"softmax\"):\n",
    "    W = tf.get_variable(\"W\", [state_size, num_classes])\n",
    "    b = tf.get_variable(\"b\", [num_classes], initializer=tf.constant_initializer(0.0))\n",
    "logits = [tf.matmul(rnn_output, W) + b for rnn_output in rnn_outputs]\n",
    "predictions = [tf.nn.softmax(logit) for logit in logits]\n",
    "\n",
    "# Turn our y placeholder into a list of labels\n",
    "y_as_list = tf.unstack(y, num=num_steps, axis=1)\n",
    "\n",
    "# losses and train_step\n",
    "losses = [tf.nn.sparse_softmax_cross_entropy_with_logits(labels=label, logits=logit) for \\\n",
    "         logit, label in zip(logits, y_as_list)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "train_step = tf.train.AdagradOptimizer(learning_rate).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train the network\n",
    "\"\"\"\n",
    "\n",
    "def train_network(num_epochs, num_steps, state_size=4, verbose=True):\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        training_losses = []\n",
    "        for idx, epoch in enumerate(gen_epochs(num_epochs, num_steps)):\n",
    "            training_loss = 0\n",
    "            training_state = np.zeros((batch_size, state_size))\n",
    "            if verbose:\n",
    "                print(\"\\nEPOCH\", idx)\n",
    "            for step, (X,Y) in enumerate(epoch):\n",
    "                tf_losses, training_loss_, training_state, _ = \\\n",
    "                    sess.run([losses,\n",
    "                              total_loss,\n",
    "                              final_state,\n",
    "                              train_step],\n",
    "                                feed_dict={x:X, y:Y, init_state:training_state})\n",
    "                training_loss += training_loss_\n",
    "                if step % 100 == 0 and step > 0:\n",
    "                    if verbose:\n",
    "                        print(\"Average loss at step\", step, \"for last 250 steps:\", training_loss/100)\n",
    "                    training_losses.append(training_loss/100)\n",
    "                    training_loss = 0\n",
    "                    \n",
    "    return training_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\\nEPOCH', 0)\n",
      "('Average loss at step', 100, 'for last 250 steps:', 0.57602105140686033)\n",
      "('Average loss at step', 200, 'for last 250 steps:', 0.52228545486927036)\n",
      "('Average loss at step', 300, 'for last 250 steps:', 0.52090810537338261)\n",
      "('Average loss at step', 400, 'for last 250 steps:', 0.52001592576503752)\n",
      "('Average loss at step', 500, 'for last 250 steps:', 0.5212795925140381)\n",
      "('Average loss at step', 600, 'for last 250 steps:', 0.52041964620351788)\n",
      "('Average loss at step', 700, 'for last 250 steps:', 0.52090629041194914)\n",
      "('Average loss at step', 800, 'for last 250 steps:', 0.51908336997032167)\n",
      "('Average loss at step', 900, 'for last 250 steps:', 0.52009309321641917)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x11057f4d0>]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1057401d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_losses = train_network(1,num_steps)\n",
    "plt.plot(training_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
